import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

def calculate_improved_congestion_index(df, method='enhanced'):
    """
    æ”¹è¿›çš„æ‹¥æŒ¤æŒ‡æ•°è®¡ç®—æ–¹æ³•
    
    Parameters:
    method: 'enhanced' | 'nonlinear' | 'adaptive' | 'original'
    """
    
    if method == 'enhanced':
        # æ–¹æ¡ˆ1ï¼šé™ä½k_jamé˜ˆå€¼ï¼Œè°ƒæ•´æƒé‡
        def kjam_enhanced(row):
            # é™ä½é˜ˆå€¼ï¼Œæé«˜æ•æ„Ÿæ€§
            base = {1: 100, 2: 80, 3: 60, 4: 40}[row['road_type_code']]
            return base
        
        df['k_jam'] = df.apply(kjam_enhanced, axis=1)
        df['speed_factor'] = (1 - df['avg_speed_kph'] / df['JAM_SPEED']).clip(lower=0, upper=1)
        df['density_factor'] = (df['traffic_density_vpkm'] / df['k_jam']).clip(upper=1)
        
        # è°ƒæ•´æƒé‡ï¼Œå¯†åº¦å æ›´å¤§æ¯”é‡
        Î± = 0.3  # é€Ÿåº¦æƒé‡é™ä½
        df['congestion_index'] = Î± * df['speed_factor'] + (1-Î±) * df['density_factor']
        
    elif method == 'nonlinear':
        # æ–¹æ¡ˆ2ï¼šéçº¿æ€§å˜æ¢ï¼Œä½¿ç”¨å¹³æ–¹æ ¹å¢å¼ºæ•æ„Ÿæ€§
        def kjam_original(row):
            base = {1: 150, 2: 120, 3: 100, 4: 70}[row['road_type_code']]
            return base
        
        df['k_jam'] = df.apply(kjam_original, axis=1)
        
        # éçº¿æ€§å˜æ¢
        speed_factor_raw = (1 - df['avg_speed_kph'] / df['JAM_SPEED']).clip(lower=0, upper=1)
        density_factor_raw = (df['traffic_density_vpkm'] / df['k_jam']).clip(upper=1)
        
        # ä½¿ç”¨å¹³æ–¹æ ¹å˜æ¢å¢å¼ºä½å€¼åŒºé—´çš„æ•æ„Ÿæ€§
        df['speed_factor'] = np.sqrt(speed_factor_raw)
        df['density_factor'] = np.sqrt(density_factor_raw)
        
        Î± = 0.4
        df['congestion_index'] = Î± * df['speed_factor'] + (1-Î±) * df['density_factor']
        
    elif method == 'adaptive':
        # æ–¹æ¡ˆ3ï¼šåˆ†é“è·¯ç±»å‹è‡ªé€‚åº”å‚æ•°
        road_params = {
            1: {'k_jam': 120, 'speed_weight': 0.4, 'nonlinear_power': 0.7},  # é«˜é€Ÿè·¯
            2: {'k_jam': 90,  'speed_weight': 0.3, 'nonlinear_power': 0.8},  # ä¸»å¹²é“  
            3: {'k_jam': 70,  'speed_weight': 0.3, 'nonlinear_power': 0.9},  # æ¬¡å¹²é“
            4: {'k_jam': 50,  'speed_weight': 0.2, 'nonlinear_power': 1.0}   # æ”¯è·¯
        }
        
        congestion_indices = []
        for _, row in df.iterrows():
            road_type = row['road_type_code']
            params = road_params[road_type]
            
            k_jam = params['k_jam']
            speed_weight = params['speed_weight']
            power = params['nonlinear_power']
            
            speed_factor = (1 - row['avg_speed_kph'] / row['JAM_SPEED'])
            speed_factor = max(0, min(1, speed_factor)) ** power
            
            density_factor = min(1, row['traffic_density_vpkm'] / k_jam) ** power
            
            cong_index = speed_weight * speed_factor + (1 - speed_weight) * density_factor
            congestion_indices.append(cong_index)
        
        df['congestion_index'] = congestion_indices
        
        # é‡æ–°è®¡ç®—å› å­ç”¨äºåˆ†æ
        df['k_jam'] = df['road_type_code'].map({k: v['k_jam'] for k, v in road_params.items()})
        df['speed_factor'] = [(1 - row['avg_speed_kph'] / row['JAM_SPEED']) for _, row in df.iterrows()]
        df['density_factor'] = [row['traffic_density_vpkm'] / row['k_jam'] for _, row in df.iterrows()]
        
    else:  # original
        # åŸå§‹æ–¹æ³•
        def kjam_original(row):
            base = {1: 150, 2: 120, 3: 100, 4: 70}[row['road_type_code']]
            return base
        
        df['k_jam'] = df.apply(kjam_original, axis=1)
        df['speed_factor'] = (1 - df['avg_speed_kph'] / df['JAM_SPEED']).clip(lower=0, upper=1)
        df['density_factor'] = (df['traffic_density_vpkm'] / df['k_jam']).clip(upper=1)
        
        Î± = 0.5
        df['congestion_index'] = Î± * df['speed_factor'] + (1-Î±) * df['density_factor']
    
    return df

def compare_congestion_methods(df, sample_size=10000):
    """
    æ¯”è¾ƒä¸åŒæ‹¥æŒ¤æŒ‡æ•°è®¡ç®—æ–¹æ³•
    """
    methods = ['original', 'enhanced', 'nonlinear', 'adaptive']
    method_names = ['åŸå§‹æ–¹æ³•', 'å¢å¼ºæ–¹æ³•', 'éçº¿æ€§æ–¹æ³•', 'è‡ªé€‚åº”æ–¹æ³•']
    
    # æŠ½æ ·æ•°æ®ç”¨äºæ¯”è¾ƒ
    df_sample = df.sample(n=min(sample_size, len(df)), random_state=42)
    
    results = {}
    
    print("ä¸åŒæ–¹æ³•è®¡ç®—ç»“æœå¯¹æ¯”ï¼š")
    print("="*70)
    
    for i, method in enumerate(methods):
        df_method = df_sample.copy()
        df_method = calculate_improved_congestion_index(df_method, method=method)
        
        # æ·»åŠ æ‹¥æŒ¤ç­‰çº§
        def get_congestion_level(cong_index):
            if cong_index < 0.2:
                return 'ç•…é€š'
            elif cong_index < 0.4:
                return 'ç¼“è¡Œ' 
            elif cong_index < 0.6:
                return 'æ‹¥æŒ¤'
            elif cong_index < 0.8:
                return 'ä¸¥é‡æ‹¥æŒ¤'
            else:
                return 'æåº¦æ‹¥æŒ¤'
        
        df_method['CongLevel'] = df_method['congestion_index'].apply(get_congestion_level)
        
        # ç»Ÿè®¡ç»“æœ
        results[method] = {
            'mean': df_method['congestion_index'].mean(),
            'std': df_method['congestion_index'].std(),
            'median': df_method['congestion_index'].median(),
            'max': df_method['congestion_index'].max(),
            'level_dist': df_method['CongLevel'].value_counts(normalize=True),
            'road_type_mean': df_method.groupby('road_type_code')['congestion_index'].mean()
        }
        
        print(f"\nğŸ“Š {method_names[i]}:")
        print(f"   å‡å€¼: {results[method]['mean']:.3f}")
        print(f"   æ ‡å‡†å·®: {results[method]['std']:.3f}")  
        print(f"   ä¸­ä½æ•°: {results[method]['median']:.3f}")
        print(f"   æœ€å¤§å€¼: {results[method]['max']:.3f}")
        
        level_dist = results[method]['level_dist'] * 100
        print(f"   æ‹¥æŒ¤ç­‰çº§åˆ†å¸ƒ:")
        for level in ['ç•…é€š', 'ç¼“è¡Œ', 'æ‹¥æŒ¤', 'ä¸¥é‡æ‹¥æŒ¤', 'æåº¦æ‹¥æŒ¤']:
            if level in level_dist:
                print(f"     {level}: {level_dist[level]:.1f}%")
    
    return results

def visualize_method_comparison(df, sample_size=10000):
    """
    å¯è§†åŒ–ä¸åŒæ–¹æ³•çš„å¯¹æ¯”
    """
    methods = ['original', 'enhanced', 'nonlinear', 'adaptive']
    method_names = ['åŸå§‹æ–¹æ³•', 'å¢å¼ºæ–¹æ³•', 'éçº¿æ€§æ–¹æ³•', 'è‡ªé€‚åº”æ–¹æ³•']
    colors = ['blue', 'green', 'orange', 'red']
    
    df_sample = df.sample(n=min(sample_size, len(df)), random_state=42)
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('ä¸åŒæ‹¥æŒ¤æŒ‡æ•°è®¡ç®—æ–¹æ³•å¯¹æ¯”', fontsize=16, fontweight='bold')
    
    # å­˜å‚¨å„æ–¹æ³•çš„ç»“æœ
    method_results = {}
    
    for method in methods:
        df_method = df_sample.copy()
        df_method = calculate_improved_congestion_index(df_method, method=method)
        method_results[method] = df_method['congestion_index']
    
    # 1. åˆ†å¸ƒå¯¹æ¯”ï¼ˆç›´æ–¹å›¾ï¼‰
    for i, method in enumerate(methods):
        axes[0, 0].hist(method_results[method], bins=30, alpha=0.7, 
                       label=method_names[i], color=colors[i], density=True)
    axes[0, 0].set_title('æ‹¥æŒ¤æŒ‡æ•°åˆ†å¸ƒå¯¹æ¯”')
    axes[0, 0].set_xlabel('æ‹¥æŒ¤æŒ‡æ•°')
    axes[0, 0].set_ylabel('å¯†åº¦')
    axes[0, 0].legend()
    
    # 2. ç®±çº¿å›¾å¯¹æ¯”
    data_for_box = [method_results[method] for method in methods]
    box_plot = axes[0, 1].boxplot(data_for_box, labels=method_names, patch_artist=True)
    for patch, color in zip(box_plot['boxes'], colors):
        patch.set_facecolor(color)
        patch.set_alpha(0.7)
    axes[0, 1].set_title('æ‹¥æŒ¤æŒ‡æ•°ç®±çº¿å›¾å¯¹æ¯”')
    axes[0, 1].set_ylabel('æ‹¥æŒ¤æŒ‡æ•°')
    axes[0, 1].tick_params(axis='x', rotation=45)
    
    # 3. ç´¯ç§¯åˆ†å¸ƒå‡½æ•°å¯¹æ¯”
    for i, method in enumerate(methods):
        sorted_values = np.sort(method_results[method])
        cumulative = np.arange(1, len(sorted_values) + 1) / len(sorted_values)
        axes[1, 0].plot(sorted_values, cumulative, label=method_names[i], 
                       color=colors[i], linewidth=2)
    axes[1, 0].set_title('ç´¯ç§¯åˆ†å¸ƒå‡½æ•°å¯¹æ¯”')
    axes[1, 0].set_xlabel('æ‹¥æŒ¤æŒ‡æ•°')
    axes[1, 0].set_ylabel('ç´¯ç§¯æ¦‚ç‡')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)
    
    # 4. ç»Ÿè®¡é‡å¯¹æ¯”é›·è¾¾å›¾
    stats_data = []
    for method in methods:
        values = method_results[method]
        stats = [
            values.mean() * 5,  # æ”¾å¤§5å€ä¾¿äºæ˜¾ç¤º
            values.std() * 10,  # æ”¾å¤§10å€ä¾¿äºæ˜¾ç¤º
            (values > 0.2).mean() * 100,  # éç•…é€šæ¯”ä¾‹
            (values > 0.4).mean() * 100,  # æ‹¥æŒ¤åŠä»¥ä¸Šæ¯”ä¾‹
            values.max() * 100  # æœ€å¤§å€¼ç™¾åˆ†æ¯”
        ]
        stats_data.append(stats)
    
    # ç®€åŒ–ç‰ˆé›·è¾¾å›¾ï¼ˆæ¡å½¢å›¾æ›¿ä»£ï¼‰
    x_labels = ['å‡å€¼Ã—5', 'æ ‡å‡†å·®Ã—10', 'éç•…é€š%', 'æ‹¥æŒ¤%', 'æœ€å¤§å€¼%']
    x_pos = np.arange(len(x_labels))
    
    bar_width = 0.2
    for i, method in enumerate(methods):
        axes[1, 1].bar(x_pos + i * bar_width, stats_data[i], 
                      bar_width, label=method_names[i], color=colors[i], alpha=0.7)
    
    axes[1, 1].set_title('ç»Ÿè®¡é‡å¯¹æ¯”')
    axes[1, 1].set_xlabel('ç»Ÿè®¡æŒ‡æ ‡')
    axes[1, 1].set_ylabel('æ•°å€¼')
    axes[1, 1].set_xticks(x_pos + bar_width * 1.5)
    axes[1, 1].set_xticklabels(x_labels, rotation=45)
    axes[1, 1].legend()
    
    plt.tight_layout()
    plt.show()

def recommend_best_method(comparison_results):
    """
    æ¨èæœ€ä½³æ–¹æ³•
    """
    print("\n" + "="*50)
    print("           æ–¹æ³•æ¨èåˆ†æ")
    print("="*50)
    
    # åˆ†æå„æ–¹æ³•çš„ç‰¹ç‚¹
    analyses = {}
    
    for method, results in comparison_results.items():
        mean_val = results['mean']
        std_val = results['std']
        max_val = results['max']
        
        # è®¡ç®—éç•…é€šæ¯”ä¾‹
        non_smooth_ratio = 1 - results['level_dist'].get('ç•…é€š', 0)
        
        # è®¡ç®—é“è·¯ç±»å‹åŒºåˆ†åº¦ï¼ˆæ ‡å‡†å·®ï¼‰
        road_type_std = results['road_type_mean'].std()
        
        analyses[method] = {
            'discrimination': road_type_std,  # åŒºåˆ†åº¦
            'sensitivity': std_val,  # æ•æ„Ÿæ€§
            'coverage': non_smooth_ratio,  # è¦†ç›–åº¦
            'range_utilization': max_val  # èŒƒå›´åˆ©ç”¨ç‡
        }
    
    # è¯„åˆ†ç³»ç»Ÿ
    method_scores = {}
    method_names = {
        'original': 'åŸå§‹æ–¹æ³•',
        'enhanced': 'å¢å¼ºæ–¹æ³•', 
        'nonlinear': 'éçº¿æ€§æ–¹æ³•',
        'adaptive': 'è‡ªé€‚åº”æ–¹æ³•'
    }
    
    print("\nå„æ–¹æ³•è¯„ä¼°:")
    for method, analysis in analyses.items():
        # ç»¼åˆè¯„åˆ†ï¼ˆå½’ä¸€åŒ–ååŠ æƒï¼‰
        score = (
            analysis['discrimination'] * 0.3 +  # åŒºåˆ†åº¦æƒé‡30%
            analysis['sensitivity'] * 0.25 +    # æ•æ„Ÿæ€§æƒé‡25%
            analysis['coverage'] * 0.25 +       # è¦†ç›–åº¦æƒé‡25%
            analysis['range_utilization'] * 0.2  # èŒƒå›´åˆ©ç”¨ç‡æƒé‡20%
        )
        
        method_scores[method] = score
        
        print(f"\nğŸ” {method_names[method]}:")
        print(f"   åŒºåˆ†åº¦: {analysis['discrimination']:.4f}")
        print(f"   æ•æ„Ÿæ€§: {analysis['sensitivity']:.4f}")  
        print(f"   è¦†ç›–åº¦: {analysis['coverage']:.3f}")
        print(f"   èŒƒå›´åˆ©ç”¨ç‡: {analysis['range_utilization']:.3f}")
        print(f"   ç»¼åˆè¯„åˆ†: {score:.4f}")
    
    # æ¨èæœ€ä½³æ–¹æ³•
    best_method = max(method_scores.keys(), key=lambda k: method_scores[k])
    
    print(f"\nğŸ† æ¨èæ–¹æ³•: {method_names[best_method]}")
    print(f"ğŸ“ˆ æ¨èç†ç”±:")
    
    if best_method == 'enhanced':
        print("   - é€šè¿‡é™ä½k_jamé˜ˆå€¼æé«˜äº†æ•æ„Ÿæ€§")
        print("   - è°ƒæ•´æƒé‡çªå‡ºå¯†åº¦å› ç´ çš„é‡è¦æ€§")
        print("   - è®¡ç®—ç®€å•ï¼Œæ˜“äºå®ç°å’Œç†è§£")
    elif best_method == 'nonlinear':
        print("   - éçº¿æ€§å˜æ¢å¢å¼ºäº†ä½å€¼åŒºé—´çš„åŒºåˆ†åº¦")
        print("   - æ›´å¥½åœ°åæ˜ äº†æ‹¥æŒ¤ç¨‹åº¦çš„æ¸è¿›æ€§")
        print("   - æ•°å­¦ä¸Šæ›´åŠ åˆç†")
    elif best_method == 'adaptive':
        print("   - é’ˆå¯¹ä¸åŒé“è·¯ç±»å‹å®šåˆ¶å‚æ•°")
        print("   - æœ€å¤§åŒ–å„ç±»é“è·¯çš„åŒºåˆ†æ•ˆæœ")
        print("   - ç¬¦åˆå®é™…äº¤é€šç‰¹å¾")
    else:
        print("   - ä¿æŒäº†åŸæœ‰çš„è®¡ç®—é€»è¾‘")
        print("   - ç»“æœç¨³å®šå¯é ")
    
    return best_method

# ä½¿ç”¨ç¤ºä¾‹ï¼š
# results = compare_congestion_methods(df)
# visualize_method_comparison(df)
# best_method = recommend_best_method(results)

def apply_recommended_method(df, method='adaptive'):
    """
    åº”ç”¨æ¨èçš„æ–¹æ³•é‡æ–°è®¡ç®—æ‹¥æŒ¤æŒ‡æ•°
    """
    print(f"åº”ç”¨{method}æ–¹æ³•é‡æ–°è®¡ç®—æ‹¥æŒ¤æŒ‡æ•°...")
    
    df_new = calculate_improved_congestion_index(df.copy(), method=method)
    
    # æ·»åŠ æ‹¥æŒ¤ç­‰çº§
    def get_congestion_level(cong_index):
        if cong_index < 0.2:
            return 'ç•…é€š'
        elif cong_index < 0.4:
            return 'ç¼“è¡Œ'
        elif cong_index < 0.6:
            return 'æ‹¥æŒ¤'
        elif cong_index < 0.8:
            return 'ä¸¥é‡æ‹¥æŒ¤'
        else:
            return 'æåº¦æ‹¥æŒ¤'
    
    df_new['CongLevel'] = df_new['congestion_index'].apply(get_congestion_level)
    
    return df_new

def analyze_and_export_congestion_data():
    """
    åˆ†æé€Ÿåº¦å±æ€§æ•°æ®å¹¶å¯¼å‡ºæ‹¥æŒ¤æŒ‡æ•°ç»“æœ
    """
    # è¯»å–æ•°æ®
    input_file = r"data\02é‡å‘½å.csv"
    output_file = r"data\03æ‹¥æŒ¤.csv"
    
    print(f"æ­£åœ¨è¯»å–æ•°æ®: {input_file}")
    try:
        df = pd.read_csv(input_file, encoding='utf-8')
    except UnicodeDecodeError:
        df = pd.read_csv(input_file, encoding='gbk')
    
    print(f"æ•°æ®shape: {df.shape}")
    print(f"åˆ—å: {list(df.columns)}")
    
    # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
    required_columns = ['avg_speed_kph', 'traffic_density_vpkm', 'road_type_code']
    missing_columns = [col for col in required_columns if col not in df.columns]
    
    if missing_columns:
        print(f"è­¦å‘Š: ç¼ºå°‘å¿…è¦åˆ— {missing_columns}")
        print("è¯·ç¡®è®¤æ•°æ®æ–‡ä»¶åŒ…å«ä»¥ä¸‹åˆ—: avg_speed_kph, traffic_density_vpkm, road_type_code")
        return
    
    # æ ¹æ®é“è·¯ç±»å‹ç”ŸæˆJAM_SPEED
    print("\næ­£åœ¨æ ¹æ®é“è·¯ç±»å‹ç”ŸæˆJAM_SPEED...")
    def get_jam_speed(road_type):
        jam_speed_map = {1: 30, 2: 30, 3: 20, 4: 15}
        return jam_speed_map.get(road_type, 20)  # é»˜è®¤å€¼20
    
    df['JAM_SPEED'] = df['road_type_code'].apply(get_jam_speed)
    print(f"å·²ç”ŸæˆJAM_SPEEDåˆ—ï¼Œå„é“è·¯ç±»å‹å¯¹åº”é€Ÿåº¦:")
    for road_type in sorted(df['road_type_code'].unique()):
        jam_speed = get_jam_speed(road_type)
        print(f"  é“è·¯ç±»å‹{road_type}: {jam_speed}km/h")
    
    # æ•°æ®é¢„å¤„ç†
    print("\næ­£åœ¨è¿›è¡Œæ•°æ®é¢„å¤„ç†...")
    required_columns.append('JAM_SPEED')  # æ·»åŠ JAM_SPEEDåˆ°å¿…è¦åˆ—
    df = df.dropna(subset=required_columns)
    print(f"å»é™¤ç¼ºå¤±å€¼åæ•°æ®shape: {df.shape}")
    
    # æ¯”è¾ƒä¸åŒæ–¹æ³•
    print("\nå¼€å§‹æ¯”è¾ƒä¸åŒæ‹¥æŒ¤æŒ‡æ•°è®¡ç®—æ–¹æ³•...")
    results = compare_congestion_methods(df, sample_size=min(10000, len(df)))
    
    # å¯è§†åŒ–å¯¹æ¯”
    print("\næ­£åœ¨ç”Ÿæˆå¯¹æ¯”å›¾è¡¨...")
    visualize_method_comparison(df, sample_size=min(10000, len(df)))
    
    # æ¨èæœ€ä½³æ–¹æ³•
    print("\næ­£åœ¨åˆ†ææ¨èæœ€ä½³æ–¹æ³•...")
    best_method = recommend_best_method(results)
    
    # åº”ç”¨æ¨èæ–¹æ³•è®¡ç®—å…¨éƒ¨æ•°æ®
    print(f"\næ­£åœ¨åº”ç”¨{best_method}æ–¹æ³•è®¡ç®—å…¨éƒ¨æ•°æ®çš„æ‹¥æŒ¤æŒ‡æ•°...")
    df_final = apply_recommended_method(df, method=best_method)
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š æœ€ç»ˆç»“æœç»Ÿè®¡:")
    print(f"æ€»è®°å½•æ•°: {len(df_final)}")
    print(f"æ‹¥æŒ¤æŒ‡æ•°ç»Ÿè®¡:")
    print(f"  å‡å€¼: {df_final['congestion_index'].mean():.3f}")
    print(f"  æ ‡å‡†å·®: {df_final['congestion_index'].std():.3f}")
    print(f"  æœ€å°å€¼: {df_final['congestion_index'].min():.3f}")
    print(f"  æœ€å¤§å€¼: {df_final['congestion_index'].max():.3f}")
    
    print(f"\næ‹¥æŒ¤ç­‰çº§åˆ†å¸ƒ:")
    level_counts = df_final['CongLevel'].value_counts()
    for level in ['ç•…é€š', 'ç¼“è¡Œ', 'æ‹¥æŒ¤', 'ä¸¥é‡æ‹¥æŒ¤', 'æåº¦æ‹¥æŒ¤']:
        if level in level_counts:
            count = level_counts[level]
            percentage = count / len(df_final) * 100
            print(f"  {level}: {count} ({percentage:.1f}%)")
    
    print(f"\nå„é“è·¯ç±»å‹æ‹¥æŒ¤æŒ‡æ•°å‡å€¼:")
    road_type_stats = df_final.groupby('road_type_code')['congestion_index'].agg(['mean', 'std', 'count'])
    for road_type in sorted(df_final['road_type_code'].unique()):
        stats = road_type_stats.loc[road_type]
        print(f"  é“è·¯ç±»å‹{road_type}: å‡å€¼={stats['mean']:.3f}, æ ‡å‡†å·®={stats['std']:.3f}, è®°å½•æ•°={stats['count']}")
    
    # å¯¼å‡ºç»“æœ
    print(f"\næ­£åœ¨å¯¼å‡ºç»“æœåˆ°: {output_file}")
    df_final.to_csv(output_file, index=False, encoding='utf-8-sig')
    print("âœ… å¯¼å‡ºå®Œæˆ!")
    
    return df_final

if __name__ == "__main__":
    # è®¾ç½®ä¸­æ–‡å­—ä½“
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
    plt.rcParams['axes.unicode_minus'] = False
    
    # æ‰§è¡Œåˆ†æ
    result_df = analyze_and_export_congestion_data()